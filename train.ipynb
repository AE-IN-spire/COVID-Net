{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet_v2 import ResNet50V2\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Flatten\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os, pathlib\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: ./output/lr0.0003\n"
     ]
    }
   ],
   "source": [
    "# TO-DO: add argparse when converting to script\n",
    "num_classes = 4\n",
    "batch_size = 8\n",
    "epochs = 50\n",
    "lr = 0.0003\n",
    "checkpoint = ''\n",
    "outputPath = './output/'\n",
    "runID = 'lr' + str(lr)\n",
    "runPath = outputPath + runID\n",
    "pathlib.Path(runPath).mkdir(parents=True, exist_ok=True)\n",
    "print('Output: ' + runPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "x_train = np.load('data/x_train.npy')\n",
    "x_test = np.load('data/x_test.npy')\n",
    "y_train = np.load('data/y_train.npy')\n",
    "y_test = np.load('data/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(runPath):\n",
    "    callbacks = []\n",
    "    lr_schedule = ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=5, min_lr=0.000001, min_delta=1e-2)\n",
    "    callbacks.append(lr_schedule) # reduce learning rate when stuck\n",
    "\n",
    "    # Callback: save checkpoints '/cp-{epoch:02d}-{val_loss:.2f}.ckpt'\n",
    "    checkpoint_path = runPath + '/cp-{epoch:02d}-{val_loss:.2f}.hdf5'\n",
    "    callbacks.append(keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "        verbose=1, save_best_only=False, save_weights_only=True, mode='min', period=1))\n",
    "\n",
    "    class SaveAsCKPT(keras.callbacks.Callback):\n",
    "        def __init__(self):\n",
    "            self.saver = tf.train.Saver()\n",
    "            self.sess = keras.backend.get_session()\n",
    "\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            checkpoint_path = runPath + '/cp-{:02d}.ckpt'.format(epoch)\n",
    "            save_path = self.saver.save(self.sess, checkpoint_path)\n",
    "    callbacks.append(SaveAsCKPT())\n",
    "\n",
    "    return callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO: add checkpoint\n",
    "base_model = ResNet50V2(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "#x = GlobalAveragePooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=lr, amsgrad=True)\n",
    "callbacks = get_callbacks(runPath)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy']) # TO-DO: add additional metrics for COVID-19\n",
    "print('Ready for training!')\n",
    "datagen = ImageDataGenerator(rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                             # randomly shift images horizontally (fraction of total width)\n",
    "                             width_shift_range=0.1,\n",
    "                             # randomly shift images vertically (fraction of total height)\n",
    "                             height_shift_range=0.1,\n",
    "                             brightness_range=[0.8,1.2], # 1.0 means no change, >1 increase in brightness\n",
    "                             # set mode for filling points outside the input boundaries\n",
    "                             fill_mode='nearest',\n",
    "                             cval=0.,  # value used for fill_mode = \"constant\"\n",
    "                             horizontal_flip=True,  # randomly flip images\n",
    "                             vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(x_train)\n",
    "\n",
    "class_weight = {0: 2.,\n",
    "                1: 2.,\n",
    "                2: 1.,\n",
    "                3: 50.}\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "'''model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                 batch_size=batch_size),\n",
    "                    callbacks=callbacks,\n",
    "                    epochs=epochs,\n",
    "                    class_weight=class_weight,\n",
    "                    validation_data=(x_test, y_test))'''\n",
    "model.fit(x_train, y_train, batch_size=batch_size, callbacks=callbacks, epochs=epochs, class_weight=class_weight, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = model.predict(x_test)\n",
    "#matrix = metrics.confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "cm_norm = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matrix)\n",
    "class_acc = np.array(cm_norm.diagonal())\n",
    "print('Normal: {0:.3f}, Bacterial: {1:.3f}, Viral: {2:.3f}, COVID-19: {3:.3f}'.format(class_acc[0],\n",
    "                                                                                      class_acc[1],\n",
    "                                                                                      class_acc[2],\n",
    "                                                                                      class_acc[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "sess = tf.Session()\n",
    "saver = tf.train.import_meta_graph(runPath + '/cp-49.ckpt.meta')\n",
    "saver.restore(sess, runPath + '/cp-49.ckpt')\n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "with open('graph.csv', mode='w') as graph_file:\n",
    "    writer = csv.writer(graph_file)\n",
    "    for tensor in tf.contrib.graph_editor.get_tensors(graph):\n",
    "        writer.writerow([str(tensor.name), tensor.shape])\n",
    "\n",
    "writer = tf.summary.FileWriter(runPath, sess.graph)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf1.15)",
   "language": "python",
   "name": "tf1.15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
